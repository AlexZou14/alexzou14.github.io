---
permalink: /
title: ""
excerpt: "Bio"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<!-- bundle exec jekyll serve -->
I am Wenbin Zou, a Ph.D. student at the South China University of Technology, supervised by [Prof. Hongxia Gao](https://yanzhao.scut.edu.cn/open/ExpertInfo.aspx?zjbh=H81zJI-Popn6WACrL7cWMw==). My primary research interests include computer vision and deep learning, mainly focusing on image restoration, image generation and related vision problems. I am looking for overseas exchanges and cooperation. My resume is as follows: [CV](../files/WenbinZouCV_20231101_.pdf)

Welcome to contact me through WeChat. My WeChat account is AlexZou14. 

# üìù Arxiv&Publications
<p style='text-align: justify;'> My research works are dedicated to: (1) Performing extreme low-light vision enhancement, under degraded conditions. (2) Generative Models for Image Generation/Editing/Enhancement. (3) Image Restoration under Complex Degradation Models.</p>

<style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none !important;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none !important;
    }
    table,td,th,tr{
    	border:none !important;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    papertitle_just {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700;
    text-align: justify
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
</style>
<!-- ################################  CONTENT START  ##################################################-->
<!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"> -->

<tbody>





<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="https://ieeexplore.ieee.org/document/9786841">
    <papertitle_just>Joint Wavelet Sub-bands Guided Network for Single Image Super-Resolution</papertitle_just>     
  </a>
  <br>
<strong>Wenbin Zou</strong>, Liang Chen, Yi Wu, Yunchen Zhang, Yuxiang Xu, Jun Shao.
<br>
<em>IEEE TMM</em> 2022 <br>
<a href="https://ieeexplore.ieee.org/document/9786841">PDF</a>
|
<a href="">code</a>
<p>This paper propose a novel CNN-based super-resolution method named joint wavelet sub-bands guided network (JWSGN). We separate the different frequency information of the image by the WT and then recover this information by a multi-branch network.</p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  

<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="">
    <papertitle_just>VQCNIR: Clearer Night Image Restoration with Vector-Quantized Dictionary</papertitle_just>
  </a>
  <br>
<strong>Wenbin Zou</strong>, Hongxia Gao, Liang Chen, Tian Ye, Weipeng Yang, Shasha Huang, Hongshen Chen.
  <br>
<em>AAAI</em>, 2024 <br>
<a href="https://arxiv.org/pdf/2312.08606">PDF</a>
|
<a href="https://github.com/AlexZou14/VQCNIR">code</a>
<p></p>
</td>



<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Zou_SDWNet_A_Straight_Dilated_Network_With_Wavelet_Transformation_for_Image_ICCVW_2021_paper.pdf">
    <papertitle_just>Sdwnet: A straight dilated network with wavelet transformation for image deblurring</papertitle_just>     
  </a>
  <br>
<strong>Wenbin Zou</strong>, Mingchao Jiang, Yunchen Zhang, Liang Chen, Zhiyong Lu, Yi Wu.
  <br>
<em>ICCVW</em> 2021 <br>
<a href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Zou_SDWNet_A_Straight_Dilated_Network_With_Wavelet_Transformation_for_Image_ICCVW_2021_paper.pdf">PDF</a>
|
<a href="https://github.com/FlyEgle/SDWNet">code</a>
<p>SDWNet uses dilated convolution to enable the obtainment of the large receptive field with high spatial resolution. Through making full use of the different receptive fields, our method can achieve better performance.</p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  


<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Zou_Self-Calibrated_Efficient_Transformer_for_Lightweight_Super-Resolution_CVPRW_2022_paper.pdf">
    <papertitle_just>Self-calibrated efficient transformer for lightweight super-resolution </papertitle_just>     
  </a>
  <br>
<strong>Wenbin Zou</strong>, Tian Ye, Weixin Zheng, Yunchen Zhang, Liang Chen, Yi Wu.
  <br>
<em>CVPRW</em> 2022 <br>
<a href="https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/papers/Zou_Self-Calibrated_Efficient_Transformer_for_Lightweight_Super-Resolution_CVPRW_2022_paper.pdf">PDF</a>
|
<a href="https://github.com/AlexZou14/SCET">code</a>
|
<p> We present a lightweight Self-Calibrated Efficient Transformer (SCET) network to solve that existing method can entail high computational costs and memory storage.</p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  





<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Zou_Cross-View_Hierarchy_Network_for_Stereo_Image_Super-Resolution_CVPRW_2023_paper.pdf">
    <papertitle_just> Cross-View Hierarchy Network for Stereo Image Super-Resolution </papertitle_just>     
  </a>
  <br>
<strong>Wenbin Zou</strong>, Hongxia Gao, Liang Chen, Yunchen Zhang, Mingchao Jiang, Zhongxin Yu, Ming Tan.
  <br>
<em>CVPRW</em> 2023 <br>
<a href="https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Zou_Cross-View_Hierarchy_Network_for_Stereo_Image_Super-Resolution_CVPRW_2023_paper.pdf">PDF</a>
|
<a href="https://github.com/AlexZou14/CVHSSR">code</a>
<p>We explore the interdependencies between various hierarchies from intra-view and propose a novel method, named Cross-View-Hierarchy Network for Stereo Image Super-Resolution (CVHSSR).</p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  






<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="">
    <papertitle_just>Multi-Scale Gamma Enhancement Network for Low-light Image Enhancement</papertitle_just>     
  </a>
  <br>
<strong>Wenbin Zou</strong>, Hongxia Gao, Weipeng Yang, Shasha Huang, Hongshen Chen, Jianliang Ma
  <br>
<em>IEEE TMM Under Review</em> <br>
<a href="">PDF</a>
|
<a href="">code</a>
<!-- <a href="https://arxiv.org/pdf/2305.09533.pdf">PDF</a> -->
<!-- <a href="https://github.com/Owen718/NightHazeFormer">code</a>
<p>NightHazeFormer generates non-learnable prior queries that effectively guides the model to learn abundant prior features from input nighttime hazy images.</p> -->
<p></p>
</td>


<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  





<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  
<!-- ###################################################################################################-->
<!-- Paper IV Reflectance, AAAI'23 -->
<!-- <tr onmouseout="aaai23_reflectance_stop()" onmouseover="aaai23_reflectance_start()" > -->


<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="https://link.springer.com/chapter/10.1007/978-3-031-44210-0_33">
    <papertitle_just>Joint Edge-Guided and Spectral Transformation Network for Self-supervised X-Ray Image Restoration </papertitle_just>     
  </a>
  <br>
Shasha Huang, <strong>Wenbin Zou</strong>, Hongxia Gao, Weipeng Yang, Hongsheng Chen, Shicheng Niu, Tian Qi, Jianliang Ma. 
  <br>
<em>ICANN</em> 2023 <br>
<a href="https://link.springer.com/chapter/10.1007/978-3-031-44210-0_33">PDF</a>

<p>To address the insufficient denoising of existing methods, we propose a novel self-supervised restoration method called the Joint Edge-guided and Spectral Transformation Network, which integrates edge guidance and spectral transformation techniques to restore color X-ray images.</p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  




<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
</td>
<td valign="top" width="80%">
  <a href="">
    <papertitle_just>Joint Priors-Based Restoration Method for Degraded Images Under Medium Propagation</papertitle_just>     
  </a>
  <br>
Hongsheng Chen, <strong>Wenbin Zou</strong>, Hongxia Gao, Weipeng Yang, Shasha Huang, Jianliang Ma
  <br>
<em>PRCV,</em> 2023 <br>
<a href="">PDF</a>

<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
</td>
<td valign="top" width="80%">
  <a href="">
    <papertitle_just>Multi-Level Feature Fusion Network for Lightweight Stereo Image Super-Resolution</papertitle_just>     
  </a>
  <br>Yunxiang Li,* ,<strong>Wenbin Zou,‚àó</strong>, Qiaomu Wei,‚àó, Feng Huang ,Jing Wu
  <br>
<em>CVPRW,</em> 2024 <br>
<a href="">PDF</a>

<p></p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->


<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
</td>
<td valign="top" width="80%">
  <a href="https://diglib.eg.org/xmlui/handle/10.1111/cgf14960">
    <papertitle_just>Enhancing Low-Light Images: A Variation-based Retinex with Modified Bilateral Total Variation and Tensor Sparse Coding </papertitle_just>     
  </a>
  <br>
Weipeng Yang, Hongxia Gao, <strong>Wenbin Zou</strong>, Shasha Huang, Hongsheng Chen, Jianliang Ma
  <br>
<em>PG,</em> 2023 <br>
<a href="https://diglib.eg.org/xmlui/handle/10.1111/cgf14960">PDF</a>
|
<a href="">code</a>
<p></p>
</td>

<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="">
    <papertitle_just>Low-Light Image Enhancement via Weighted Low-Rank Tensor Regularized Retinex Model</papertitle_just>     
  </a>
  <br>
Weipeng Yang, Hongxia Gao, <strong>Wenbin Zou</strong>ÔºåTongtong Liu, Shasha Huang, Jianliang Ma
  <br>
<em>ICMR</em>, 2024 <br>
<a href="">PDF</a>
|
<a href="">code</a>
<p></p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->
  
<!-- ###################################################################################################-->
<!-- Paper V ShadowDiffusion-->
<!-- <tr onmouseout="submit23_shadowdiffusion_stop()" onmouseover="submit23_shadowdiffusion_start()" > -->
<td width="20%">
<!-- <div class="one"> -->
<!-- <div class="two" id = 'submit23_shadowdiffusion_image'><img src='./files/submit23_after.png'></div>
<img src='./files/submit23_before.png'> -->
<!-- </div> -->
<script type="text/javascript">
// function submit23_shadowdiffusion_start() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "1";
// }
// function submit23_shadowdiffusion_stop() {
// document.getElementById('submit23_shadowdiffusion_image').style.opacity = "0";
// }
// submit23_shadowdiffusion_stop()
</script>
</td>
<td valign="top" width="80%">
  <a href="https://dl.acm.org/doi/10.1145/3581783.3611742">
    <papertitle_just>Sequential Affinity Learning for Video Restoration</papertitle_just>     
  </a>
  <br>
Tian Ye, SiXiang Chen, Yun Liu, Wenhao Chai, Jinbin Bai, <strong>Wenbin Zou</strong>, Yunchen Zhang, jiang mingchao, Erkang Chen, Chenghao Xue
  <br>
<em>ACM Multimedia (ACM MM),</em> 2023 <br>
<a href="https://dl.acm.org/doi/10.1145/3581783.3611742">PDF</a>
|
<a href="">code</a>
<p></p>
</td>

<!-- Paper V ShadowDiffusion -->
<!-- ###################################################################################################-->



</tbody>


# üéñ Competitions & Awards
- The 1st of Citrus Flower and Fruit Shoot Semantic Segmentation Challenge Based on Visible Light Images. October 2023.
- The 1st of Baidu Netdisk AI Competition: Beauty, freckle and acne removal. September 2023.
- The 1st award of the China International Big Data Industry ExpoÔºöthe Data Scenario Application Innovation Contest. May 2023.
- The 8th of the NTIRE 2023 Challenge on Stereo Image Super-Resolution, Track 1. April 2023.
- The 5th of the NTIRE 2023 Challenge on Stereo Image Super-Resolution, Track 2.
- The 4th of the NTIRE 2023 Challenge on Stereo Image Super-Resolution, Track 3.
- The 2nd award of "Xingzhi Cup" National Artificial Intelligence Innovation and Application Competition. February 2023.
- The 1st of Baidu Netdisk AI Competition: Document Image Deblurring. September 2022.
- The 6th of Baidu Netdisk AI Competition: Image Processing Challenge-Document Image Direction Recognition. September 2022.
- The 7th of AIM 2022 Compressed Input Super-Resolution Challenge, Track 1. July 2022.
- The 3rd of 2022 CVPR Neural Architecture Search (NAS) Track 1: Supernet Track. May 2022.
- The 1st award of AI Innovation and Application Competition, China information and Communication Research Institute. December 2021.
- The 12th "Challenge Cup" College Student Entrepreneur Competition, Bronze award, Ministry of Education. November 2020.
  
# üßë‚Äçü§ù‚Äçüßë My Friends
- [Tian Ye](https://owen718.github.io/) @HKUST(GZ)
- [Sixiang Chen](https://sixiangchen.com) @HKUST(GZ)
- [Yunchen Zhang](https://scholar.google.com/citations?user=GogMKLIAAAAJ&hl=en)@ZTE 
- [Mingchao Jiang](https://scholar.google.com/citations?user=-Br9r7-SC6cC&hl=en)@GUT

# üí¨ Academic Services
- Conference Reviewer: ICCVW, PRCV
- Journal Reviewer: 
  
  IEEE Trans. on Neural Networks and Learning Systems.

  IEEE Trans. on Circuits and Systems for Video Technology 


# üìñ Educations
- Sep'2022-Now: Ph.D. (Electronic Information Engineering), South China University of Technology, Guangzhou, China. Supervisor: Hongxia Gao.
- Sep'2019-Jul'2022: M.Sc. (Information and Communication Engineering), Fujian Normal University, Fuzhou, China. Supervisor: LiangChen and Yi Wu.
- Sep‚Äô2015-Jul‚Äô2019: B.Eng (Electronic Information Engineering), Hefei Normal University, Hefei, China.

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=nO2OglnuM0fvvpRYJbg2jk7y5alRISB3tXeKoWNcxCc&cl=ffffff&w=a"></script>